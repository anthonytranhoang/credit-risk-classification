# credit-risk-classification
In this project, I have used a classification model on 2 classes, High risk loan labels and healthy loan labels. 

From what I found, the precision on Healthy loan labels were immaculate. The high risk loan labels were also very accurate but, there were the occasional error or mistake.

The models accuracy predicted 99% of instances from both models. 

For the macro average, this is the unweighted average of the precision, recall, and F1-score for both classes, showing a strong overall performance with a macro average F1-score of 0.95.

For the weighted average, this is the average of the metrics weighted by the number of instances (support) for each class. Given the large class imbalance (with class 0 making up the vast majority of the data), the weighted average reflects the overall performance better, with a near-perfect accuracy of 0.99.

Overall, this model has showed outstanding results.
